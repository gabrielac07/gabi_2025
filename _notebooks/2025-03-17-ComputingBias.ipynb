{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "layout: post\n",
    "title: P2 Computing Bias (2025)\n",
    "permalink: /compbias/\n",
    "author: Avika, Gabi, Zoe\n",
    "toc: true\n",
    "comments: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìå What is Computing Bias?\n",
    "> **Bias:** An inclination or prejudice in favor of or against a person or a group of people, typically in a way that is unfair.\n",
    "\n",
    "Computing **bias** occurs when computer programs, algorithms, or systems produce results that unfairly favor or disadvantage certain groups. This bias can result from **biased data, flawed design, or unintended consequences** of programming.\n",
    "\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/aeBLboArW8c?si=No1ZvRCvxdiEmbZB\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n",
    "\n",
    "---\n",
    "\n",
    "## üé• Example: Netflix Recommendation Bias\n",
    "Netflix provides content recommendations to users through algorithms. However, these algorithms can introduce bias in several ways:  \n",
    "\n",
    "### üîç **How Bias Can Occur:**\n",
    "- **Majority Preference Bias:**  \n",
    "  - Recommending mostly popular content, making it hard for less popular or niche content to be discovered.  \n",
    "- **Filtering Bias:**  \n",
    "  - Filtering out content that doesn‚Äôt fit a user‚Äôs perceived interests based on limited viewing history.  \n",
    "  - For example, if a user primarily watches romantic comedies, Netflix may avoid suggesting documentaries or foreign films, even if the user would enjoy them.  \n",
    "\n",
    "---\n",
    "\n",
    "# üßê How Does Computing Bias Happen?\n",
    "Computing bias can occur for various reasons, including:  \n",
    "\n",
    "### üìÇ **1. Unrepresentative or Incomplete Data:**  \n",
    "- Algorithms trained on data that **doesn't represent real-world diversity** will produce biased results.  \n",
    "\n",
    "### üìâ **2. Flawed or Biased Data:**  \n",
    "- Historical or existing prejudices reflected in the training data can lead to biased outputs.  \n",
    "\n",
    "### üìù **3. Data Collection & Labeling:**  \n",
    "- Human annotators may introduce biases due to different cultural or personal biases during the data labeling process.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä **Explicit Data vs. Implicit Data**\n",
    "\n",
    "### üìù **Explicit Data**\n",
    "**Definition:** Data that the user or programmer **directly provides**.\n",
    "\n",
    "- **Example:** On Netflix, users input personal information such as **name**, **age**, and **preferences**. They can also **rate shows** or **movies**.\n",
    "\n",
    "### üîç **Implicit Data**\n",
    "**Definition:** Data that is **inferred** from the user's actions or behavior, not directly provided.\n",
    "\n",
    "- **Example:** Netflix tracks your **viewing history**, **watch time**, and **interactions** with content. This data is then used to **recommend shows and movies** that Netflix thinks you might like.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öñÔ∏è **Implications**\n",
    "- **Implicit Data** can lead to reinforcing **bias** by suggesting content based on **past behavior**, potentially **limiting diversity** and preventing users from discovering new genres.\n",
    "- **Explicit Data** is generally more **accurate** but can still be biased if **user input is limited** or influenced by the **design of the platform**.\n",
    "\n",
    "---\n",
    "## ü§î Popcorn Hack #1\n",
    "\n",
    "**What is an example of Explicit Data?**\n",
    "\n",
    "A) Netflix recommends shows based on your viewing history.  \n",
    "B) You provide your name, age, and preferences when creating a Netflix account.  \n",
    "C) Netflix tracks the time you spend watching certain genres.\n",
    "\n",
    "<div class=\"flip-container\">\n",
    "    <div class=\"flipper\">\n",
    "        <div class=\"front\">\n",
    "            <button class=\"button\" onclick=\"flipCard()\">Show Answer</button>\n",
    "        </div>\n",
    "        <div class=\"back\">\n",
    "            The answer is: B) You provide your name, age, and preferences when creating a Netflix account. This is an example of **explicit data**, as it is directly provided by the user.\n",
    "        </div>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<script>\n",
    "    function flipCard() {\n",
    "        const flipContainer = event.target.closest('.flip-container');\n",
    "        flipContainer.classList.toggle('flipped');\n",
    "    }\n",
    "</script>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Types of Bias\n",
    "\n",
    "> **ü§ñ Algorithmic Bias**  \n",
    "- <ins>Algorithmic bias</ins> is bias generated from a repeatable but faulty **computer system** that produces inaccurate results.\n",
    "    - Example: A hiring algorithm at Apple is trained on past employee data but the data shows that male candidates were hired more often than female candidates. Because of this, the system would favor male candidates over female candidates because historical hiring practices were biased toward men.\n",
    "> **üìà Data Bias**  \n",
    "- <ins>Data bias</ins> occurs when the data itself includes bias caused by **incomplete or erroneous information**.\n",
    "    - Example: A healthcare AI model predicts lower disease risk for certain populations. Since the AI model hasn't been introduced to other demographics, it would assume that data should include patients from a specific demographic, and not consider others.\n",
    "> **üß† Cognitive Bias**  \n",
    "- <ins>Cognitive bias</ins> is when the person unintentionally introduces **their own bias** in the data.\n",
    "    - Example: A researcher conducting a study on social media usage unconsciously selects data that supports their belief that too much screen time leads to lower grades. This is a form of cognitive bias called confirmation bias because the researcher is searching for information to support their beliefs.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## ü§î Popcorn Hack #2\n",
    "\n",
    "**What is an example of Data Bias?**\n",
    "\n",
    "A) A hiring algorithm favors male candidates because the training data contains a disproportionate number of male resumes.  \n",
    "B) A system is trained on a dataset where certain groups, such as people with darker skin tones, are underrepresented.  \n",
    "C) A researcher intentionally selects data that supports their own beliefs about the impact of screen time on grades.\n",
    "\n",
    "<div class=\"flip-container\">\n",
    "    <div class=\"flipper\">\n",
    "        <div class=\"front\">\n",
    "            <button class=\"button\" onclick=\"flipCard()\">Reveal Answer</button>\n",
    "        </div>\n",
    "        <div class=\"back\">\n",
    "            The answer is: B) A system is trained on a dataset where certain groups, such as people with darker skin tones, are underrepresented. This leads to the system performing poorly for these groups, which is an example of Data Bias.\n",
    "        </div>\n",
    "    </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "    /* Style for the button */\n",
    "    .button {\n",
    "        padding: 6px 12px;\n",
    "        font-size: 14px;\n",
    "        color: white;\n",
    "        background-color: #555; /* Dark gray */\n",
    "        border: none;\n",
    "        border-radius: 4px;\n",
    "        cursor: pointer;\n",
    "        transition: background-color 0.3s ease;\n",
    "        text-align: center;\n",
    "    }\n",
    "\n",
    "    .button:hover {\n",
    "        background-color: #333; /* Even darker gray */\n",
    "    }\n",
    "\n",
    "    /* Container for the flip effect */\n",
    "    .flip-container {\n",
    "        perspective: 1000px;\n",
    "        margin: 20px 0;\n",
    "    }\n",
    "\n",
    "    .flipper {\n",
    "        width: 100%;\n",
    "        height: 70px;\n",
    "        transform-style: preserve-3d;\n",
    "        transition: transform 0.6s;\n",
    "        display: flex;\n",
    "        justify-content: center;\n",
    "        align-items: center;\n",
    "    }\n",
    "\n",
    "    /* Initially, the answer side is hidden */\n",
    "    .front, .back {\n",
    "        position: absolute;\n",
    "        backface-visibility: hidden;\n",
    "        width: 100%;\n",
    "        height: 100%;\n",
    "        display: flex;\n",
    "        justify-content: center;\n",
    "        align-items: center;\n",
    "        font-size: 16px;\n",
    "        font-family: 'Arial', sans-serif;\n",
    "        padding: 15px;\n",
    "        border-radius: 8px;\n",
    "    }\n",
    "\n",
    "    /* Front of the card (button) */\n",
    "    .front {\n",
    "        background-color: #666; /* Medium gray */\n",
    "        color: white;\n",
    "        border: 2px solid #444; /* Dark gray border */\n",
    "    }\n",
    "\n",
    "    /* Back of the card (answer) */\n",
    "    .back {\n",
    "        background-color: #777; /* Light gray */\n",
    "        color: white;\n",
    "        transform: rotateY(180deg);\n",
    "    }\n",
    "\n",
    "    /* Flipped state */\n",
    "    .flipped .flipper {\n",
    "        transform: rotateY(180deg);\n",
    "    }\n",
    "\n",
    "    /* Card container for question text */\n",
    "    .question-container {\n",
    "        margin: 20px;\n",
    "        font-size: 18px;\n",
    "        color: #333;\n",
    "        font-family: 'Arial', sans-serif;\n",
    "        line-height: 1.6;\n",
    "        font-weight: 500;\n",
    "    }\n",
    "\n",
    "    /* Heading styling */\n",
    "    .heading {\n",
    "        font-size: 24px;\n",
    "        color: #333;\n",
    "        font-family: 'Arial', sans-serif;\n",
    "        margin-bottom: 20px;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "## Intentional Bias vs Unintentional Bias\n",
    "\n",
    "> **Intentional Bias:** The deliberate introduction of prejudice or unfairness into algorithms or systems, often by individuals or organizations, to achieve a specific outcome or advantage.\n",
    "\n",
    "Example: Imagine a company using a hiring algorithm to screen job applicants.\n",
    "- **Goal of the algorithm:** Select the most qualified candidates based on their resumes and experience.\n",
    "- However, the people who create this algorithm might intentionally (or unknowingly) include factors that are biased toward certain groups.\n",
    "\n",
    "For example, if the algorithm is designed to prioritize resumes with certain words or experiences that are more common among a specific gender or ethnic group, it might unfairly favor candidates from that group over others.\n",
    "\n",
    "Also, if the algorithm gives extra weight to leadership positions in high-profile companies that are predominantly male or white, it may unintentionally (but intentionally by the developers) disadvantage women or people of color who have the same qualifications but worked in different environments.\n",
    "\n",
    "> **Unintentional Bias:** Occurs when algorithms, often trained on flawed or incomplete data, produce results that unfairly discriminate against certain groups.\n",
    "\n",
    "Example: A facial recognition software.\n",
    "- **Goal of the program:** Designed to identify people based on their facial features.\n",
    "- However, if the software is trained using a large dataset of photos primarily of one race, it can have trouble identifying individuals who look different.\n",
    "\n",
    "For example, if the software is trained using pictures of people but the majority of those photos are of lighter-skinned individuals, the system may have trouble accurately recognizing people with darker skin tones.\n",
    "\n",
    "This unintentional bias happens because the developers didn‚Äôt purposefully choose to exclude people with darker skin, but because the dataset they used happened to be unbalanced.\n",
    "\n",
    "As a result, the system works better for lighter-skinned people and struggles with darker-skinned people, even though the goal is to treat everyone equally.\n",
    "\n",
    "---\n",
    "\n",
    "## ü§î Popcorn Hack #3\n",
    "\n",
    "**What is an example of Unintentional Bias?**\n",
    "\n",
    "A) A social media algorithm prioritizes content from a specific group of influencers because of their background.  \n",
    "B) A facial recognition system works better for lighter-skinned individuals because of an unbalanced dataset.  \n",
    "C) A hiring algorithm is designed to give preference to candidates from a specific ethnicity.\n",
    "\n",
    "<div class=\"flip-container\">\n",
    "    <div class=\"flipper\">\n",
    "        <div class=\"front\">\n",
    "            <button class=\"button\" onclick=\"flipCard()\">Show Answer</button>\n",
    "        </div>\n",
    "        <div class=\"back\">\n",
    "            The answer is: B) A facial recognition system works better for lighter-skinned individuals because of an unbalanced dataset. This is an example of unintentional bias, as the system was not purposefully designed to favor one group over another, but the dataset led to biased results.\n",
    "        </div>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<script>\n",
    "    function flipCard() {\n",
    "        const flipContainer = event.target.closest('.flip-container');\n",
    "        flipContainer.classList.toggle('flipped');\n",
    "    }\n",
    "</script>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mitigation Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìö **Computing Bias - Homework Questions**\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **Multiple-Choice Questions**  \n",
    "\n",
    "**1. What is computing bias?**  \n",
    "A. A mistake in the code causing a program to crash.  \n",
    "B. A program or algorithm producing results that favor or disadvantage certain groups.  \n",
    "C. A technical error in hardware causing malfunctions.  \n",
    "D. The act of manually inputting incorrect data.  \n",
    "\n",
    "---\n",
    "\n",
    "**2. What is the primary cause of bias in computing systems?**  \n",
    "A. Poor internet connection.  \n",
    "B. Unrepresentative or incomplete data used to train algorithms.  \n",
    "C. Efficient programming techniques.  \n",
    "D. Increased processing power.  \n",
    "\n",
    "---\n",
    "\n",
    "**3. Which of the following is an example of implicit data collection?**  \n",
    "A. Filling out a survey about your favorite movies.  \n",
    "B. Clicking ‚Äúlike‚Äù on a specific genre on Netflix.  \n",
    "C. Netflix tracking your watch history and suggesting similar shows.  \n",
    "D. Manually selecting your preferred language on a streaming platform.  \n",
    "\n",
    "---\n",
    "\n",
    "**4. What is a common issue when algorithms are trained on biased datasets?**  \n",
    "A. They run faster.  \n",
    "B. They become more accurate.  \n",
    "C. They can reinforce existing societal biases.  \n",
    "D. They use less memory.  \n",
    "\n",
    "---\n",
    "\n",
    "**5. Which of the following could help reduce computing bias in recommendation systems?**  \n",
    "A. Ignoring user preferences.  \n",
    "B. Only using data from popular sources.  \n",
    "C. Using diverse and representative training data.  \n",
    "D. Deleting all user data.  \n",
    "\n",
    "---\n",
    "\n",
    "## ‚úçÔ∏è **Short-Answer Question**  \n",
    "\n",
    "**Explain the difference between implicit and explicit data. Provide an example of each.**  \n",
    "\n",
    "---\n",
    "\n",
    "| Criteria                         | Description                                                                                       | Points |\n",
    "|---------------------------------|---------------------------------------------------------------------------------------------------|--------|\n",
    "| **Multiple-Choice Questions (0.5 points total)** | Each correct answer is worth 0.1 points.                                                        | 0.5    |\n",
    "| - Question 1                     | Correct answer: **B**                                                                            | 0.1    |\n",
    "| - Question 2                     | Correct answer: **D**                                                                            | 0.1    |\n",
    "| - Question 3                     | Correct answer: **C**                                                                            | 0.1    |\n",
    "| - Question 4                     | Correct answer: **A**                                                                            | 0.1    |\n",
    "| - Question 5                     | Correct answer: **C**                                                                            | 0.1    |\n",
    "| **Short-Answer Question (0.5 points)**  | Explanation of implicit vs. explicit data, with accurate examples of each.                   | 0.5    |\n",
    "| - Clarity & Accuracy             | Clear, concise, and correct explanation of implicit vs. explicit data.                         | 0.25   |\n",
    "| - Examples Provided              | Provides appropriate examples for both implicit and explicit data.                             | 0.25   |\n",
    "| **Total**                        |                                                                                                   | 1.0    |\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
